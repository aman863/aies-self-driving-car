{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3YROe8OE6z3g"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile(\"../driving_dataset.zip\", 'r')\n",
    "zip_ref.extractall(\"../data\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WQR92qF6-vh"
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "import keras\n",
    "\n",
    "data = pandas.read_csv('../data/driving_dataset/data.txt',header = None,sep=' ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WJ8OWKxy6dbX"
   },
   "outputs": [],
   "source": [
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fEyJJEt27rgV",
    "outputId": "1d3b63da-6ff1-4c50-dd1c-ddea7677dbb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45406,) (45406,)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:,0]\n",
    "y_data = np.array([float(i) for i in data[:,-1]])\n",
    "print(x_data.shape,y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PJppL6je8AoO",
    "outputId": "8db4ec47-e75b-4394-fecb-601149c8e43f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36324,) (9082,) (36324,) (9082,)\n"
     ]
    }
   ],
   "source": [
    "l = (int)(x_data.shape[0]*0.8)\n",
    "xtrain = x_data[:l]\n",
    "ytrain = y_data[:l]\n",
    "xtest = x_data[l:]\n",
    "ytest = y_data[l:]\n",
    "print(xtrain.shape,xtest.shape,ytrain.shape,ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UjRmJwXz8HtV"
   },
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "c = list(zip(xtrain,ytrain))\n",
    "random.shuffle(c)\n",
    "xtrain,ytrain = zip(*c)\n",
    "\n",
    "\n",
    "c = list(zip(xtest,ytest))\n",
    "random.shuffle(c)\n",
    "xtest,ytest = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EpiWBseE8Rnf"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def LoadBatch(batch_size,i,xdata,ydata):\n",
    "  xd = []\n",
    "  yd = []\n",
    "  Pointer = 0;\n",
    "  if i==len(xdata)//batch_size - 1:\n",
    "      batch_size = len(xdata)%batch_size\n",
    "  while Pointer<batch_size:\n",
    "    img = image.load_img(\"../data/driving_dataset/\"+xdata[(Pointer+i*batch_size)%l],color_mode='rgb',target_size=[200,200])\n",
    "    img = image.img_to_array(img)/255.0\n",
    "    xd.append(img)\n",
    "    yd.append(ydata[(Pointer+i*batch_size)%l]*np.pi/180)\n",
    "    Pointer = Pointer+1\n",
    "  return np.array(xd),np.array(yd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t_ifoO7o9M7t"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D,Flatten, Dense, Dropout, BatchNormalization, LeakyReLU, MaxPool2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# from keras.adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 897
    },
    "colab_type": "code",
    "id": "IaiVk3zdhynF",
    "outputId": "d2e3cb5b-1637-4f72-92c4-04c9a4ff360a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 196, 196, 24)      1824      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 98, 98, 24)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 98, 98, 24)        96        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 94, 94, 36)        21636     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 47, 47, 36)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 47, 47, 36)        144       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 45, 48)        15600     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 22, 48)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 22, 48)        192       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 64)        27712     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 412,421\n",
      "Trainable params: 411,821\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(24,(5,5),activation='relu',input_shape=(200,200,3),kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(36,(5,5),activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(48,(3,3),activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128,(3,3),activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(64,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1,activation='tanh',kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2lCQTSdT0Tp"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(0.0001),loss = 'mse',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "J_rc_LW5T57u",
    "outputId": "0f4fd7cc-8a3e-4520-aa91-29ca3fc4f282"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 Step:0 Train loss:5.650350 Train mae:0.262177 Test loss:5.665772 Test mae:0.237859\n",
      "\n",
      "Epoch:1 Step:10 Train loss:5.816091 Train mae:0.376898 Test loss:5.634776 Test mae:0.260243\n",
      "\n",
      "Epoch:1 Step:20 Train loss:5.690842 Train mae:0.455791 Test loss:5.635510 Test mae:0.397052\n",
      "\n",
      "Epoch:1 Step:30 Train loss:5.719461 Train mae:0.496644 Test loss:5.718343 Test mae:0.430362\n",
      "\n",
      "Epoch:1 Step:40 Train loss:5.430764 Train mae:0.347173 Test loss:5.409655 Test mae:0.346206\n",
      "\n",
      "Epoch:1 Step:50 Train loss:5.503658 Train mae:0.318847 Test loss:5.254816 Test mae:0.226629\n",
      "\n",
      "Epoch:1 Step:60 Train loss:5.376624 Train mae:0.307958 Test loss:5.471498 Test mae:0.294648\n",
      "\n",
      "Epoch:1 Step:70 Train loss:5.575811 Train mae:0.599543 Test loss:5.614486 Test mae:0.602983\n",
      "\n",
      "Epoch:1 Step:80 Train loss:5.378864 Train mae:0.498136 Test loss:5.504138 Test mae:0.551051\n",
      "\n",
      "Epoch:1 Step:90 Train loss:5.363987 Train mae:0.487525 Test loss:5.420603 Test mae:0.519795\n",
      "\n",
      "Epoch:1 Step:100 Train loss:5.151326 Train mae:0.429801 Test loss:5.468933 Test mae:0.523777\n",
      "\n",
      "Epoch:1 Step:110 Train loss:5.134470 Train mae:0.361315 Test loss:5.057443 Test mae:0.392179\n",
      "\n",
      "Epoch:1 Step:120 Train loss:4.917338 Train mae:0.289151 Test loss:4.870498 Test mae:0.285740\n",
      "\n",
      "Epoch:1 Step:130 Train loss:4.888331 Train mae:0.284950 Test loss:4.868193 Test mae:0.279943\n",
      "\n",
      "Epoch:1 Step:140 Train loss:4.757948 Train mae:0.229305 Test loss:4.921411 Test mae:0.324576\n",
      "\n",
      "Epoch:1 Step:150 Train loss:5.004284 Train mae:0.348626 Test loss:4.716772 Test mae:0.279748\n",
      "\n",
      "Epoch:1 Step:160 Train loss:4.608146 Train mae:0.228265 Test loss:4.671021 Test mae:0.267343\n",
      "\n",
      "Epoch:1 Step:170 Train loss:4.593905 Train mae:0.224946 Test loss:4.688051 Test mae:0.285855\n",
      "\n",
      "Epoch:1 Step:180 Train loss:4.530369 Train mae:0.230001 Test loss:4.481647 Test mae:0.238582\n",
      "\n",
      "Epoch:1 Step:190 Train loss:4.367404 Train mae:0.206560 Test loss:4.517702 Test mae:0.276107\n",
      "\n",
      "Epoch:1 Step:200 Train loss:4.398016 Train mae:0.209338 Test loss:4.347233 Test mae:0.237477\n",
      "\n",
      "Epoch:1 Step:210 Train loss:4.321525 Train mae:0.229891 Test loss:4.313312 Test mae:0.259006\n",
      "\n",
      "Epoch:1 Step:220 Train loss:4.436634 Train mae:0.219910 Test loss:4.144618 Test mae:0.259198\n",
      "\n",
      "Epoch:1 Step:230 Train loss:4.473782 Train mae:0.224540 Test loss:4.185552 Test mae:0.265829\n",
      "\n",
      "Epoch:1 Step:240 Train loss:3.931989 Train mae:0.134211 Test loss:4.057800 Test mae:0.238608\n",
      "\n",
      "Epoch:1 Step:250 Train loss:3.902333 Train mae:0.157659 Test loss:4.123036 Test mae:0.311335\n",
      "\n",
      "Epoch:1 Step:260 Train loss:3.900905 Train mae:0.175010 Test loss:3.866188 Test mae:0.193477\n",
      "\n",
      "Epoch:1 Step:270 Train loss:3.787754 Train mae:0.154988 Test loss:3.933606 Test mae:0.247907\n",
      "\n",
      "Epoch:1 Step:280 Train loss:3.893624 Train mae:0.211048 Test loss:3.860823 Test mae:0.258265\n",
      "\n",
      "Epoch:2 Step:0 Train loss:3.675449 Train mae:0.163021 Test loss:3.674280 Test mae:0.212003\n",
      "\n",
      "Epoch:2 Step:10 Train loss:3.712274 Train mae:0.213459 Test loss:3.775948 Test mae:0.253567\n",
      "\n",
      "Epoch:2 Step:20 Train loss:3.577028 Train mae:0.161089 Test loss:3.700787 Test mae:0.260621\n",
      "\n",
      "Epoch:2 Step:30 Train loss:3.518763 Train mae:0.178072 Test loss:3.503372 Test mae:0.208852\n",
      "\n",
      "Epoch:2 Step:40 Train loss:3.362327 Train mae:0.133652 Test loss:3.521481 Test mae:0.245932\n",
      "\n",
      "Epoch:2 Step:50 Train loss:3.414686 Train mae:0.170916 Test loss:3.474523 Test mae:0.228220\n",
      "\n",
      "Epoch:2 Step:60 Train loss:3.281022 Train mae:0.155194 Test loss:3.326143 Test mae:0.194276\n",
      "\n",
      "Epoch:2 Step:70 Train loss:3.271684 Train mae:0.165043 Test loss:3.357745 Test mae:0.249228\n",
      "\n",
      "Epoch:2 Step:80 Train loss:3.133462 Train mae:0.163378 Test loss:3.257291 Test mae:0.250189\n",
      "\n",
      "Epoch:2 Step:90 Train loss:3.167496 Train mae:0.170059 Test loss:3.117565 Test mae:0.210307\n",
      "\n",
      "Epoch:2 Step:100 Train loss:3.025761 Train mae:0.136977 Test loss:3.011207 Test mae:0.200814\n",
      "\n",
      "Epoch:2 Step:110 Train loss:3.062996 Train mae:0.160574 Test loss:3.039090 Test mae:0.225303\n",
      "\n",
      "Epoch:2 Step:120 Train loss:2.889373 Train mae:0.138029 Test loss:2.990048 Test mae:0.239659\n",
      "\n",
      "Epoch:2 Step:130 Train loss:2.878536 Train mae:0.173855 Test loss:3.038965 Test mae:0.245737\n",
      "\n",
      "Epoch:2 Step:140 Train loss:2.801208 Train mae:0.133222 Test loss:2.785014 Test mae:0.191654\n",
      "\n",
      "Epoch:2 Step:150 Train loss:2.988583 Train mae:0.233076 Test loss:2.730865 Test mae:0.209259\n",
      "\n",
      "Epoch:2 Step:160 Train loss:2.698167 Train mae:0.160751 Test loss:2.694515 Test mae:0.182271\n",
      "\n",
      "Epoch:2 Step:170 Train loss:2.669344 Train mae:0.160901 Test loss:2.746166 Test mae:0.226131\n",
      "\n",
      "Epoch:2 Step:180 Train loss:2.616916 Train mae:0.174809 Test loss:2.632864 Test mae:0.226894\n",
      "\n",
      "Epoch:2 Step:190 Train loss:2.491184 Train mae:0.143377 Test loss:2.617139 Test mae:0.247580\n",
      "\n",
      "Epoch:2 Step:200 Train loss:2.546754 Train mae:0.165004 Test loss:2.510969 Test mae:0.208388\n",
      "\n",
      "Epoch:2 Step:210 Train loss:2.450500 Train mae:0.173355 Test loss:2.478896 Test mae:0.225811\n",
      "\n",
      "Epoch:2 Step:220 Train loss:2.619231 Train mae:0.160616 Test loss:2.785032 Test mae:0.350323\n",
      "\n",
      "Epoch:2 Step:230 Train loss:2.678762 Train mae:0.174917 Test loss:2.325517 Test mae:0.208846\n",
      "\n",
      "Epoch:2 Step:240 Train loss:2.159702 Train mae:0.092420 Test loss:2.321075 Test mae:0.212267\n",
      "\n",
      "Epoch:2 Step:250 Train loss:2.134761 Train mae:0.102596 Test loss:2.388330 Test mae:0.252801\n",
      "\n",
      "Epoch:2 Step:260 Train loss:2.160208 Train mae:0.144666 Test loss:2.179991 Test mae:0.224877\n",
      "\n",
      "Epoch:2 Step:270 Train loss:2.072168 Train mae:0.130573 Test loss:2.081743 Test mae:0.210769\n",
      "\n",
      "Epoch:2 Step:280 Train loss:2.181242 Train mae:0.150600 Test loss:2.125745 Test mae:0.216724\n",
      "\n",
      "Epoch:3 Step:0 Train loss:1.981821 Train mae:0.111420 Test loss:2.260301 Test mae:0.287404\n",
      "\n",
      "Epoch:3 Step:10 Train loss:2.025430 Train mae:0.180551 Test loss:2.176574 Test mae:0.278461\n",
      "\n",
      "Epoch:3 Step:20 Train loss:1.935351 Train mae:0.141836 Test loss:2.338107 Test mae:0.333468\n",
      "\n",
      "Epoch:3 Step:30 Train loss:1.883258 Train mae:0.151823 Test loss:2.033122 Test mae:0.290758\n",
      "\n",
      "Epoch:3 Step:40 Train loss:1.764809 Train mae:0.109006 Test loss:2.067542 Test mae:0.318732\n",
      "\n",
      "Epoch:3 Step:50 Train loss:1.820563 Train mae:0.139158 Test loss:1.884078 Test mae:0.242551\n",
      "\n",
      "Epoch:3 Step:60 Train loss:1.721891 Train mae:0.122274 Test loss:1.736107 Test mae:0.198939\n",
      "\n",
      "Epoch:3 Step:70 Train loss:1.734329 Train mae:0.131725 Test loss:1.793190 Test mae:0.244353\n",
      "\n",
      "Epoch:3 Step:80 Train loss:1.613658 Train mae:0.120411 Test loss:1.763140 Test mae:0.233126\n",
      "\n",
      "Epoch:3 Step:90 Train loss:1.677410 Train mae:0.138268 Test loss:1.597171 Test mae:0.180226\n",
      "\n",
      "Epoch:3 Step:100 Train loss:1.560890 Train mae:0.104822 Test loss:1.722730 Test mae:0.236608\n",
      "\n",
      "Epoch:3 Step:110 Train loss:1.623019 Train mae:0.142206 Test loss:1.807923 Test mae:0.337955\n",
      "\n",
      "Epoch:3 Step:120 Train loss:1.472889 Train mae:0.124383 Test loss:1.576171 Test mae:0.230866\n",
      "\n",
      "Epoch:3 Step:130 Train loss:1.483307 Train mae:0.147196 Test loss:1.642535 Test mae:0.255637\n",
      "\n",
      "Epoch:3 Step:140 Train loss:1.441791 Train mae:0.128597 Test loss:1.646452 Test mae:0.255099\n",
      "\n",
      "Epoch:3 Step:150 Train loss:1.640103 Train mae:0.211079 Test loss:1.500886 Test mae:0.235989\n",
      "\n",
      "Epoch:3 Step:160 Train loss:1.376972 Train mae:0.138097 Test loss:1.706023 Test mae:0.323629\n",
      "\n",
      "Epoch:3 Step:170 Train loss:1.370791 Train mae:0.152188 Test loss:1.341470 Test mae:0.204069\n",
      "\n",
      "Epoch:3 Step:180 Train loss:1.330369 Train mae:0.142198 Test loss:1.280345 Test mae:0.207423\n",
      "\n",
      "Epoch:3 Step:190 Train loss:1.240833 Train mae:0.131389 Test loss:1.721548 Test mae:0.359438\n",
      "\n",
      "Epoch:3 Step:200 Train loss:1.319670 Train mae:0.153782 Test loss:1.400159 Test mae:0.242400\n",
      "\n",
      "Epoch:3 Step:210 Train loss:1.240243 Train mae:0.146489 Test loss:1.530107 Test mae:0.345532\n",
      "\n",
      "Epoch:3 Step:220 Train loss:1.442609 Train mae:0.140618 Test loss:1.356967 Test mae:0.255108\n",
      "\n",
      "Epoch:3 Step:230 Train loss:1.526025 Train mae:0.158974 Test loss:1.628504 Test mae:0.344224\n",
      "\n",
      "Epoch:3 Step:240 Train loss:1.025721 Train mae:0.071597 Test loss:1.121881 Test mae:0.188577\n",
      "\n",
      "Epoch:3 Step:250 Train loss:1.026538 Train mae:0.101129 Test loss:1.082134 Test mae:0.194928\n",
      "\n",
      "Epoch:3 Step:260 Train loss:1.071320 Train mae:0.126253 Test loss:1.211797 Test mae:0.274634\n",
      "\n",
      "Epoch:3 Step:270 Train loss:1.005195 Train mae:0.113040 Test loss:1.266414 Test mae:0.246752\n",
      "\n",
      "Epoch:3 Step:280 Train loss:1.140413 Train mae:0.146459 Test loss:1.087369 Test mae:0.220197\n",
      "\n",
      "Epoch:4 Step:0 Train loss:0.943516 Train mae:0.082563 Test loss:1.057501 Test mae:0.205869\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4 Step:10 Train loss:1.002444 Train mae:0.154005 Test loss:1.224704 Test mae:0.283867\n",
      "\n",
      "Epoch:4 Step:20 Train loss:0.938047 Train mae:0.109551 Test loss:0.983625 Test mae:0.195473\n",
      "\n",
      "Epoch:4 Step:30 Train loss:0.910158 Train mae:0.148328 Test loss:1.136324 Test mae:0.276964\n",
      "\n",
      "Epoch:4 Step:40 Train loss:0.807517 Train mae:0.075512 Test loss:0.979436 Test mae:0.244969\n",
      "\n",
      "Epoch:4 Step:50 Train loss:0.886995 Train mae:0.117724 Test loss:1.015953 Test mae:0.243193\n",
      "\n",
      "Epoch:4 Step:60 Train loss:0.813731 Train mae:0.112907 Test loss:0.797309 Test mae:0.167146\n",
      "\n",
      "Epoch:4 Step:70 Train loss:0.843970 Train mae:0.114206 Test loss:0.954856 Test mae:0.236306\n",
      "\n",
      "Epoch:4 Step:80 Train loss:0.745019 Train mae:0.112287 Test loss:0.864307 Test mae:0.212502\n",
      "\n",
      "Epoch:4 Step:90 Train loss:0.830308 Train mae:0.125036 Test loss:1.047727 Test mae:0.313098\n",
      "\n",
      "Epoch:4 Step:100 Train loss:0.732140 Train mae:0.100632 Test loss:0.739348 Test mae:0.194541\n",
      "\n",
      "Epoch:4 Step:110 Train loss:0.813011 Train mae:0.125341 Test loss:0.947168 Test mae:0.305176\n",
      "\n",
      "Epoch:4 Step:120 Train loss:0.669387 Train mae:0.096226 Test loss:0.887842 Test mae:0.274380\n",
      "\n",
      "Epoch:4 Step:130 Train loss:0.712103 Train mae:0.137765 Test loss:0.649674 Test mae:0.138668\n",
      "\n",
      "Epoch:4 Step:140 Train loss:0.684758 Train mae:0.109515 Test loss:0.904022 Test mae:0.297816\n",
      "\n",
      "Epoch:4 Step:150 Train loss:0.904367 Train mae:0.199832 Test loss:0.822765 Test mae:0.257645\n",
      "\n",
      "Epoch:4 Step:160 Train loss:0.659228 Train mae:0.128738 Test loss:0.652906 Test mae:0.184331\n",
      "\n",
      "Epoch:4 Step:170 Train loss:0.663415 Train mae:0.129458 Test loss:0.723521 Test mae:0.222046\n",
      "\n",
      "Epoch:4 Step:180 Train loss:0.642810 Train mae:0.124151 Test loss:0.766994 Test mae:0.252786\n",
      "\n",
      "Epoch:4 Step:190 Train loss:0.572471 Train mae:0.106864 Test loss:0.647172 Test mae:0.176383\n",
      "\n",
      "Epoch:4 Step:200 Train loss:0.671162 Train mae:0.144490 Test loss:0.688267 Test mae:0.215813\n",
      "\n",
      "Epoch:4 Step:210 Train loss:0.606768 Train mae:0.134737 Test loss:0.642662 Test mae:0.229202\n",
      "\n",
      "Epoch:4 Step:220 Train loss:0.828252 Train mae:0.128495 Test loss:0.542290 Test mae:0.158286\n",
      "\n",
      "Epoch:4 Step:230 Train loss:0.928745 Train mae:0.154084 Test loss:0.526400 Test mae:0.195129\n",
      "\n",
      "Epoch:4 Step:240 Train loss:0.445805 Train mae:0.073800 Test loss:0.662349 Test mae:0.247114\n",
      "\n",
      "Epoch:4 Step:250 Train loss:0.458189 Train mae:0.083743 Test loss:0.578642 Test mae:0.249896\n",
      "\n",
      "Epoch:4 Step:260 Train loss:0.521052 Train mae:0.125396 Test loss:0.762418 Test mae:0.319463\n",
      "\n",
      "Epoch:4 Step:270 Train loss:0.466796 Train mae:0.106521 Test loss:0.451099 Test mae:0.139605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 128\n",
    "num = len(xtrain)\n",
    "\n",
    "c=0\n",
    "l = len(xtest)\n",
    "\n",
    "# train over the dataset about 30 times\n",
    "for epoch in range(epochs):\n",
    "    for i in range(int(num//batch_size)):\n",
    "        xs, ys = LoadBatch(batch_size,i,xtrain,ytrain)\n",
    "        ys.reshape(-1,1)\n",
    "\n",
    "        model.fit(xs,ys,verbose=0)\n",
    "\n",
    "        if i%10 == 0:\n",
    "            score_train = model.evaluate(xs,ys,verbose=0)\n",
    "            xs1, ys1 = LoadBatch(batch_size,c,xtest,ytest)\n",
    "            c+=1\n",
    "            ys1.reshape(-1,1)\n",
    "            score_test = model.evaluate(xs1,ys1,verbose=0)\n",
    "            print(\"Epoch:%d Step:%d Train loss:%f Train mae:%f Test loss:%f Test mae:%f\\n\"%(epoch+1,i,score_train[0],score_train[1],score_test[0],score_test[1]))\n",
    "\n",
    "        if i%100 == 0:\n",
    "            model.save_weights(\"gkl7.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of selfdrivingcar2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
